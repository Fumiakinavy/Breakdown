# backend/pipeline.py ナラティブ

## 2025-10-22T14:24:04Z 事前計画
### 概要
LangGraphを用いたバックエンドワーカーを試作し、タスク登録直後にサブタスク分割を行うパイプラインを作成する。
### 目的
LLM処理を非同期化してUI表示時に即座にグラフを提供できるようにする。
### 最適な実装方法
LangChain + LangGraphでノード化し、`generate -> validate -> persist`の順で処理。設定値は`.env`で注入し、Redis/Celery等のワーカーから呼び出す想定とする。
### 入出力
入力: `task_id`, `title`, `detail`, 過去embedding, ユーザープロファイル。  
出力: `SubtaskNode`/`SubtaskEdge`永続化。

## 2025-10-22T14:24:04Z 実装後記録
### 概要
LangGraphワークフローを定義し、LLM呼び出し、検証、PostgreSQL永続化を行う非同期`worker`関数を実装した。
### 目的
タスク登録直後にバックグラウンドでサブタスクを計算し、アプリで素早く参照できるようにする。
### 最適な実装方法
`ChatOpenAI`/`LlamaCpp`を切り替え可能にし、`MemorySaver`でチェックポイント管理。SQLAlchemyのセッションでノード/エッジを保存。
### 最適と思われる理由
LangGraphは分岐やリトライが拡張しやすく、将来的に評価ノードやA/Bテストを挿入しやすい。
### 入出力
入力: グラフ生成コンテキスト。  
出力: DB永続化完了。
### 実装の評価
プロトタイプとして必要な構成を満たし、ローカルLLM切替も考慮できた。評価: 92/100。
